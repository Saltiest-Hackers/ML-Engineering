{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from decouple import config\n",
    "\n",
    "!. ../.env\n",
    "\n",
    "conn = psycopg2.connect(\"postgres://\" + config(\"POSTGRES_USERNAME\") + \":\" + config(\"POSTGRES_PASSWORD\") + \"@raja.db.elephantsql.com:5432/mozfsrjp\")\n",
    "curs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curs.close()\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions for Analyzing Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def escape_string(text):\n",
    "    if isinstance(text, str):\n",
    "        text = re.sub(r\"\\\"\", \"\\\\\\\"\", text)\n",
    "        text = re.sub(r\"'\", \"\\\\'\", text)\n",
    "        return text\n",
    "    else:\n",
    "        return \"-\"\n",
    "\n",
    "def convert_int(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def get_saltiness(x):\n",
    "    if isinstance(x, str):\n",
    "        res = analyzer.polarity_scores(x)[\"neg\"]\n",
    "        return res\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine(df):\n",
    "    \n",
    "    df = df.loc[df['type'] == 'comment']\n",
    "    df = df.loc[df['author'].isnull() == False]\n",
    "    df = df[['id', 'time', 'author', 'parent', 'text', 'type']]\n",
    "    df['parent'] = df['parent'].astype(int)    \n",
    "    return df\n",
    "\n",
    "def scrub(doc):\n",
    "    patt = {\n",
    "            \"unicode_patt\": \"&.{4}(?=;);\",\n",
    "            \"line_break\":   \"<p>\",\n",
    "            \"href_patt\":    \"<a.*</a>\",\n",
    "            \"quote\":        \"&quot;\",\n",
    "            \"html_footnote\": \"\\[.\\]\",\n",
    "            \"punctuation\":   \"[^\\w\\s]\",\n",
    "            \"numbers\":       \"[^A-Za-z\\s]\",\n",
    "        }\n",
    "    \n",
    "    r = rf'|'.join(patt.values())\n",
    "    return re.sub(r, ' ', str(doc))\n",
    "\n",
    "def process_text(df):\n",
    "    \n",
    "    # regex\n",
    "    df['processed_text'] = df['text'].apply(scrub)\n",
    "    # lowercase\n",
    "    df['processed_text'] = df['processed_text'].str.lower()\n",
    "    # double spaces\n",
    "    df['processed_text'] = df['processed_text'].str.replace(r'\\s+', ' ')\n",
    "    \n",
    "    \n",
    "    # word freq\n",
    "    word_freq = pd.Series(' '.join(df['processed_text']).split()).value_counts()\n",
    "    \n",
    "    common = list(word_freq[:10].index)\n",
    "    rare = list(word_freq[word_freq.values < 2].index)\n",
    "    \n",
    "    stop_words = list(nltk.corpus.stopwords.words('english'))    \n",
    "    stop_words = set(stop_words + common + rare)\n",
    "    \n",
    "    print('removing stopwords')\n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(stop_words))\n",
    "    \n",
    "    df['no_stopwords'] = df['processed_text'].str.replace(pat, '')\n",
    "    df['no_stopwords'] = df['no_stopwords'].str.replace(r'\\s+', ' ')\n",
    "    \n",
    "    # remove less than 2 words\n",
    "    df = df[df[\"no_stopwords\"].str.split(\" \").apply(lambda x: len(x)) > 3]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hn_df = pd.read_csv(\"../csv/most_recent_1_5mm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1000 = hn_df[\"author\"].value_counts().index[:1000]\n",
    "hn_df = hn_df[hn_df[\"author\"].isin(top_1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1040000 / 1499356 -- 69.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cowley/venv/lambda/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/cowley/venv/lambda/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/cowley/venv/lambda/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing stopwords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cowley/venv/lambda/lib/python3.6/site-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/cowley/venv/lambda/lib/python3.6/site-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1050000 / 1499356 -- 70.03%\n",
      "removing stopwords\n",
      "Batch 1060000 / 1499356 -- 70.70%\n",
      "removing stopwords\n",
      "Batch 1070000 / 1499356 -- 71.36%\n",
      "removing stopwords\n",
      "Batch 1080000 / 1499356 -- 72.03%\n",
      "removing stopwords\n",
      "Batch 1090000 / 1499356 -- 72.70%\n",
      "removing stopwords\n",
      "Batch 1100000 / 1499356 -- 73.36%\n",
      "removing stopwords\n",
      "Batch 1110000 / 1499356 -- 74.03%\n",
      "removing stopwords\n",
      "Batch 1120000 / 1499356 -- 74.70%\n",
      "removing stopwords\n",
      "Batch 1130000 / 1499356 -- 75.37%\n",
      "removing stopwords\n",
      "Batch 1140000 / 1499356 -- 76.03%\n",
      "removing stopwords\n",
      "Batch 1150000 / 1499356 -- 76.70%\n",
      "removing stopwords\n",
      "Batch 1160000 / 1499356 -- 77.37%\n",
      "removing stopwords\n",
      "Batch 1170000 / 1499356 -- 78.03%\n",
      "removing stopwords\n",
      "Batch 1180000 / 1499356 -- 78.70%\n",
      "removing stopwords\n",
      "Batch 1190000 / 1499356 -- 79.37%\n",
      "removing stopwords\n",
      "Batch 1200000 / 1499356 -- 80.03%\n",
      "removing stopwords\n",
      "Batch 1210000 / 1499356 -- 80.70%\n",
      "removing stopwords\n",
      "Batch 1220000 / 1499356 -- 81.37%\n",
      "removing stopwords\n",
      "Batch 1230000 / 1499356 -- 82.04%\n",
      "removing stopwords\n",
      "Batch 1240000 / 1499356 -- 82.70%\n",
      "removing stopwords\n",
      "Batch 1250000 / 1499356 -- 83.37%\n",
      "removing stopwords\n",
      "Batch 1260000 / 1499356 -- 84.04%\n",
      "removing stopwords\n",
      "Batch 1270000 / 1499356 -- 84.70%\n",
      "removing stopwords\n",
      "Batch 1280000 / 1499356 -- 85.37%\n",
      "removing stopwords\n",
      "Batch 1290000 / 1499356 -- 86.04%\n",
      "removing stopwords\n",
      "Batch 1300000 / 1499356 -- 86.70%\n",
      "removing stopwords\n",
      "Batch 1310000 / 1499356 -- 87.37%\n",
      "removing stopwords\n",
      "Batch 1320000 / 1499356 -- 88.04%\n",
      "removing stopwords\n",
      "Batch 1330000 / 1499356 -- 88.70%\n",
      "removing stopwords\n",
      "Batch 1340000 / 1499356 -- 89.37%\n",
      "removing stopwords\n",
      "Batch 1350000 / 1499356 -- 90.04%\n",
      "removing stopwords\n",
      "Batch 1360000 / 1499356 -- 90.71%\n",
      "removing stopwords\n",
      "Batch 1370000 / 1499356 -- 91.37%\n",
      "removing stopwords\n",
      "Batch 1380000 / 1499356 -- 92.04%\n",
      "removing stopwords\n",
      "Batch 1390000 / 1499356 -- 92.71%\n",
      "removing stopwords\n",
      "Batch 1400000 / 1499356 -- 93.37%\n",
      "removing stopwords\n",
      "Batch 1410000 / 1499356 -- 94.04%\n",
      "removing stopwords\n",
      "Batch 1420000 / 1499356 -- 94.71%\n",
      "removing stopwords\n",
      "Batch 1430000 / 1499356 -- 95.37%\n",
      "removing stopwords\n",
      "Batch 1440000 / 1499356 -- 96.04%\n",
      "removing stopwords\n",
      "Batch 1450000 / 1499356 -- 96.71%\n",
      "removing stopwords\n",
      "Batch 1460000 / 1499356 -- 97.38%\n",
      "removing stopwords\n",
      "Batch 1470000 / 1499356 -- 98.04%\n",
      "removing stopwords\n",
      "Batch 1480000 / 1499356 -- 98.71%\n",
      "removing stopwords\n",
      "Batch 1490000 / 1499356 -- 99.38%\n",
      "removing stopwords\n"
     ]
    }
   ],
   "source": [
    "from psycopg2.extras import execute_batch\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "batchsize = 10000\n",
    "\n",
    "for ix in range(1040000, len(hn_df)+1, batchsize):\n",
    "    \n",
    "    print(f\"Batch {ix} / {len(hn_df)} -- {ix/len(hn_df)*100:.2f}%\")\n",
    "    \n",
    "    batch = hn_df[ix:ix+batchsize]\n",
    "    batch = process_text(batch)\n",
    "    \n",
    "    batch = [\n",
    "        [\n",
    "            row[1][1],\n",
    "            row[1][2],\n",
    "            row[1][3],\n",
    "            row[1][4],\n",
    "            convert_int(row[1][7]),\n",
    "            get_saltiness(row[1][4]),\n",
    "        ]\n",
    "        for row in batch.iterrows()\n",
    "    ]\n",
    "    \n",
    "    batch = [\n",
    "        row for row in batch if row[-1] < 1.0\n",
    "    ]\n",
    "    \n",
    "    query = \"\"\"\n",
    "        INSERT INTO comments (id, author, time, comment_text, parent_id, saltiness)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s);\n",
    "    \"\"\"\n",
    "    \n",
    "    curs = conn.cursor()\n",
    "    execute_batch(curs, query, batch)\n",
    "    curs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM comments\n",
    "    LIMIT 1000\n",
    "\"\"\"\n",
    "curs = conn.cursor()\n",
    "curs.execute(query)\n",
    "res = curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22310905,\n",
       " 'apta',\n",
       " 1581529723,\n",
       " 'Ah yes, the alcohol excuse. Who would have thought that allowing alcohol on flights wasn&#x27;t the best idea?',\n",
       " 22309335,\n",
       " 0.0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "hn_df[\"time_dt\"] = hn_df[\"time\"].apply(datetime.utcfromtimestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_months_ago = (datetime.utcnow() - timedelta(90)).timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    DELETE FROM comments\n",
    "    WHERE comments.time < %s;\n",
    "\"\"\"\n",
    "curs = conn.cursor()\n",
    "curs.execute(query, [three_months_ago])\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(754093,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curs = conn.cursor()\n",
    "curs.execute(\"\"\"\n",
    "    SELECT COUNT(*)\n",
    "    FROM comments;\n",
    "\"\"\")\n",
    "curs.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM comments\n",
    "    WHERE saltiness != 1.0\n",
    "    ORDER BY saltiness DESC\n",
    "    LIMIT 100\n",
    "\"\"\"\n",
    "curs = conn.cursor()\n",
    "curs.execute(query)\n",
    "res = curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "DELETE FROM comments\n",
    "WHERE saltiness = 1.0;\n",
    "\"\"\"\n",
    "curs = conn.cursor()\n",
    "curs.execute(q)\n",
    "curs.close()\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(x):\n",
    "    if isinstance(x, str):\n",
    "        res = analyzer.polarity_scores(x)[\"pos\"]\n",
    "        return res\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT *\n",
    "FROM comments c\n",
    "WHERE c.saltiness < 0.1\n",
    "ORDER BY c.saltiness ASC;\n",
    "\"\"\"\n",
    "curs = conn.cursor()\n",
    "curs.execute(q)\n",
    "res = curs.fetchall()\n",
    "curs.close()\n",
    "\n",
    "batch_size = 10000\n",
    "for ix in range(0, len(res)+1, batch_size):\n",
    "    \n",
    "    batch = res[ix : ix+batch_size]\n",
    "    vals = [(get_pos(row[3]), row[0]) for row in batch]\n",
    "    \n",
    "    pos = get_pos(text)\n",
    "    q = \"\"\"\n",
    "    UPDATE comments\n",
    "    SET pos=%s\n",
    "    WHERE id=%s\n",
    "    \"\"\"\n",
    "    \n",
    "    execute_batch(q, vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(hn_df.columns).index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub(doc):\n",
    "    return re.sub(r'[^A-Za-z\\s]', '', str(doc))\n",
    "def word_frequencies(df):\n",
    "    \"\"\"Returns a dict with key, value pair of word frequencies in descending order\n",
    "    Args:\n",
    "    -----\n",
    "    df - pandas.DataFrame object\n",
    "    \"\"\"\n",
    "    ngram_vectorizer = CountVectorizer(analyzer='word',\n",
    "                                       ngram_range=(1, 1),\n",
    "                                       min_df=1)\n",
    "    X = ngram_vectorizer.fit_transform(df['text'])    \n",
    "    vocab = ngram_vectorizer.get_feature_names()\n",
    "    counts = X.sum(axis=0).A1\n",
    "    freqs = dict(Counter(dict(zip(vocab, counts))))    \n",
    "    return freqs\n",
    "def process_text(df):\n",
    "    # only those comments with not null values\n",
    "    df = df.loc[df['type'] == 'comment'][['text']]\n",
    "    df = df.dropna()    \n",
    "    # clean the text using bs4\n",
    "    df['text'] = df['text'].apply(lambda x: BeautifulSoup(x).get_text())\n",
    "    # regex remove all non-letters && to lower\n",
    "    df['text'] = df['text'].apply(scrub)\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    return df\n",
    "def remove_stops(df):\n",
    "    # start with NLTK stopwords\n",
    "    stop_words = list(nltk.corpus.stopwords.words('english'))\n",
    "    # word frequencies for the batch\n",
    "    print('Determining word frequencies')\n",
    "    freqs = word_frequencies(df)\n",
    "    # rare words\n",
    "    rare = list({key: value for key, value in freqs.items() if value < 2}.keys())\n",
    "    # common words - occur at a frequency greater than the total number of observations\n",
    "    common = list(freqs.keys())[:15]\n",
    "    # add the common and rare words to the set\n",
    "    stop_words = set(stop_words + common + rare)\n",
    "    # use regex for stopword removal\n",
    "    print(f'Removing stopwords: {len(stop_words)} total')\n",
    "#     pat = r'\\b(?:{})\\b'.format('|'.join(stop_words))\n",
    "    df['text'] = df['text'].apply(lambda x: ' '. \\\n",
    "                  join([word for word in x.split() if word not in (stop_words)]))\n",
    "#     df['text'] = df['text'].str.replace(r'\\s+', ' ')\n",
    "    # retaining comments with 30 or more words\n",
    "    df = df.loc[df['text'].apply(lambda x: len(str(x).split(\" \"))).values > 30]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cowley/venv/lambda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "sz = 1000\n",
    "res = []\n",
    "for ix in range(0, len(hn_df), sz):\n",
    "    batch = hn_df[ix : ix+sz]\n",
    "    batch[\"pos\"] = batch[\"text\"].apply(get_pos)\n",
    "    res.extend([(row[0], row[1]) for row in batch[[\"id\", \"pos\"]]])\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
